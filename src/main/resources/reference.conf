hbase-journal {

  # class name of the hbase journal plugin
  class = "akka.persistence.journal.hbase.HBaseAsyncWriteJournal"

  # Partitions will be used to avoid the "hot write region" problem.
  # Set this to a number greater than the expected number of regions of your table.
  partition.count = 5

  # Flush interval - defined how many write operations we should buffer on the client before writing to hbase
  # Use this to tine tune performance, according to the size of your Persistent messages (bigger messages = flush more often)
  # Default in the driver is 1000.
  flush-interval = 100

  # All these settings will be set on the underlying Hadoop Configuration
  hbase {
    zookeeper.quorum = "127.0.0.1"
  }

  # Name of the table to be created/used by the journal
  table = "messages"

  # Name of the family to be created/used by the journal
  family = "akka"

  # when performing scans, how many items to we want to obtain per one next(N) call
  scan-batch-size = 10

  # Dispatcher for fetching and replaying messages
  replay-dispatcher = "akka.persistence.dispatchers.default-replay-dispatcher"
}

